{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "dbd2ff9b-061d-45ee-a6f2-8d5253b34183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "6c474bf4-d183-436f-8518-2a2dbea4c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"Data_2019-20.csv\",sep=';')\n",
    "attribute_df = pd.read_csv(\"Attributes.csv\")\n",
    "sensitivity_df = pd.read_excel(\"Sensitivity_Results.xlsx\")  # columns: column_name, sensitivity_level (High/Medium/Low)\n",
    "kyu_df = pd.read_excel(\"KYU Score.xlsx\")  # columns: user_id, kyu_score (0-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "4b291265-77e5-4c08-a9d2-8eac46ad67bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitive_df = sensitivity_df[sensitivity_df['Sensitivity_Level'].isin(['High', 'Moderate'])]\n",
    "\n",
    "# Extract the attribute_id values (i.e., column names in data)\n",
    "sensi = []\n",
    "for i in sensitivity_df['Attr_id'].tolist():\n",
    "    sensi.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "26d508d1-27cf-462f-9f77-fa443f6937f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_df\n",
    "n = len(df)\n",
    "min_unique_ratio = 0.9  # adjust based on your needs\n",
    "max_unique_ratio = 0.90  # adjust based on your needs\n",
    "\n",
    "records = []\n",
    "qids = []\n",
    "\n",
    "for col in df.columns:\n",
    "    nunique = df[col].nunique(dropna=True)  # Number of unique values excluding NaN\n",
    "    ratio = nunique / n if n else 0  # Ratio of unique values to total rows\n",
    "    dtype = df[col].dtype  # Data type of the column\n",
    "    \n",
    "    records.append({\n",
    "        'column': col,\n",
    "        'dtype': str(dtype),\n",
    "        'nunique': nunique,\n",
    "        'ratio': round(ratio, 3)\n",
    "    })\n",
    "    \n",
    "    if 1 < nunique < n and min_unique_ratio <= ratio <= max_unique_ratio:\n",
    "        qids.append(col)\n",
    "\n",
    "summary_df = pd.DataFrame(records, columns=['column', 'dtype', 'nunique', 'ratio'])\n",
    "\n",
    "quasi=qids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "9c634f07-4298-4154-adcc-7a6168a4afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_user_query(result_df):\n",
    "    # Run query\n",
    "    # result_df = ps.sqldf(user_query, locals())\n",
    "    \n",
    "    # Determine result type\n",
    "    shape = result_df.shape\n",
    "    if shape[0] > 1 and shape[1] > 1:\n",
    "        output_type = \"table\"\n",
    "    elif shape[0] > 1 and shape[1] == 1:\n",
    "        output_type = \"column\"\n",
    "    elif shape[0] == 1 and shape[1] > 1:\n",
    "        output_type = \"row\"\n",
    "    else:\n",
    "        output_type = \"cell\"\n",
    "\n",
    "    return output_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "df96fc55-3bd4-4257-92d6-adebfa910432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_strategy(data_level, sensitivity, user_trust):\n",
    "    strategies = {\n",
    "        'cell': {\n",
    "            'high': {\n",
    "                'low': ['cell_suppression', 'differential_privacy_column', 'full_masking'],\n",
    "                'moderate': ['top_bottom_coding', 'microaggregation', 'partial_masking'],\n",
    "                'high': ['noise_injection']\n",
    "            },\n",
    "            'moderate': {\n",
    "                'low': ['microaggregation'],\n",
    "                'moderate': ['generalization', 'partial_masking'],\n",
    "                'high': ['no_transformation']\n",
    "            },\n",
    "            'low': {\n",
    "                'low': ['noise_injection'],\n",
    "                'moderate': ['no_transformation'],\n",
    "                'high': ['no_transformation']\n",
    "            }\n",
    "        },\n",
    "        'column': {\n",
    "            'high': {\n",
    "                'low': ['generalization', 'top_bottom_coding', 'full_masking'],\n",
    "                'moderate': ['cell_suppression', 'partial_masking'],\n",
    "                'high': ['noise_injection']\n",
    "            },\n",
    "            'moderate': {\n",
    "                'low': ['binning'],\n",
    "                'moderate': ['binning', 'partial_masking'],\n",
    "                'high': ['no_transformation']\n",
    "            },\n",
    "            'low': {\n",
    "                'low': ['generalization'],\n",
    "                'moderate': ['no_transformation'],\n",
    "                'high': ['no_transformation']\n",
    "            }\n",
    "        },\n",
    "        'row': {\n",
    "            'high': {\n",
    "                'low': ['full_masking'],\n",
    "                'moderate': ['microaggregation', 'partial_masking'],\n",
    "                'high': ['microaggregation']\n",
    "            },\n",
    "            'moderate': {\n",
    "                'low': ['generalization'],\n",
    "                'moderate': ['microaggregation', 'partial_masking'],\n",
    "                'high': ['no_transformation']\n",
    "            },\n",
    "            'low': {\n",
    "                'low': ['microaggregation'],\n",
    "                'moderate': ['no_transformation'],\n",
    "                'high': ['no_transformation']\n",
    "            }\n",
    "        },\n",
    "        'table': {\n",
    "            'high': {\n",
    "                'low': ['cell_suppression', 'differential_privacy', 'full_masking'],\n",
    "                'moderate': ['microaggregation', 'partial_masking'],\n",
    "                'high': ['microaggregation']\n",
    "            },\n",
    "            'moderate': {\n",
    "                'low': ['generalization'],\n",
    "                'moderate': ['microaggregation', 'partial_masking'],\n",
    "                'high': ['no_transformation']\n",
    "            },\n",
    "            'low': {\n",
    "                'low': ['generalization'],\n",
    "                'moderate': ['no_transformation'],\n",
    "                'high': ['no_transformation']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return strategies[data_level][sensitivity][user_trust]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "fb74f4af-e2d9-4570-aca1-8f157aa6285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_masking_cell(df, column):\n",
    "    return df[column].apply(lambda x: '*' * len(str(x)))\n",
    "\n",
    "def partial_masking_cell(df, column):\n",
    "    def mask_half(val):\n",
    "        val_str = str(val)\n",
    "        half = len(val_str) // 2\n",
    "        return '*' * half + val_str[half:]\n",
    "    return df[column].apply(mask_half)\n",
    "\n",
    "def cell_suppression(df, column, threshold=2):\n",
    "    # Suppress values that occur fewer than `threshold` times\n",
    "    value_counts = df[column].value_counts()\n",
    "    return df[column].apply(lambda x: np.nan if value_counts[x] < threshold else x)\n",
    "\n",
    "def noise_injection(df, column, epsilon=0.1):\n",
    "    if df.shape[0] == 1 and df.shape[1] == 1:\n",
    "        noise=0.85\n",
    "        df[column] = df[column] +df[column].mean()* noise\n",
    "    else:\n",
    "        # Case 2: DataFrame with more than 1 row\n",
    "        sensitivity = df[column].max() - df[column].min()\n",
    "        sensitivity = max(sensitivity, 1e-6)  # Prevent divide by zero\n",
    "        scale = sensitivity / epsilon  # Laplace scale\n",
    "        noise = np.random.laplace(loc=0, scale=scale, size=len(df))\n",
    "        df[column] = df[column] + noise\n",
    "    return df \n",
    "    \n",
    "def differential_privacy_column(df, column, epsilon=0.1):\n",
    "    # Simple Laplace noise for demo\n",
    "    return df[column] + np.random.laplace(loc=0, scale=1/epsilon, size=len(df))\n",
    "\n",
    "\n",
    "def generalization_column(df, column, bins=3):\n",
    "    # Bucket numerical values\n",
    "    return pd.cut(df[column], bins=bins, labels=[f\"Group {i+1}\" for i in range(bins)])\n",
    "\n",
    "def binning(df, column, bin_size):\n",
    "    return (df[column] // bin_size) * bin_size\n",
    "\n",
    "def top_bottom_coding(df, column, top=90, bottom=10):\n",
    "    top_val = np.percentile(df[column], top)\n",
    "    bottom_val = np.percentile(df[column], bottom)\n",
    "    return df[column].clip(lower=bottom_val, upper=top_val)\n",
    "\n",
    "def full_masking_row(df):\n",
    "    print(df.apply(lambda row: ['XXXX' for _ in row], axis=1))\n",
    "    return df.apply(lambda row: ['XXXX' for _ in row], axis=1)\n",
    "\n",
    "def partial_masking_row(df):\n",
    "    def partial(val):\n",
    "        val_str = str(val)\n",
    "        half = len(val_str) // 2\n",
    "        return '*' * half + val_str[half:]\n",
    "    return df.apply(lambda row: [partial(val) for val in row], axis=1)\n",
    "\n",
    "def microaggregation_row(df, k=2):\n",
    "    df_sorted = df.sort_values(by=df.columns[0])\n",
    "    aggregated_df = df_sorted.copy()\n",
    "    for i in range(0, len(df), k):\n",
    "        group = df_sorted.iloc[i:i+k]\n",
    "        mean_vals = group.mean(numeric_only=True)\n",
    "        for col in mean_vals.index:\n",
    "            aggregated_df.loc[group.index, col] = mean_vals[col]\n",
    "    return aggregated_df\n",
    "\n",
    "\n",
    "def full_masking_table(df):\n",
    "    return df.apply(lambda row: ['XXXX' for _ in row], axis=1)\n",
    "\n",
    "\n",
    "def partial_masking_table(df):\n",
    "    def partial(val):\n",
    "        val_str = str(val)\n",
    "        half = len(val_str) // 2\n",
    "        return '*' * half + val_str[half:]\n",
    "    return df.applymap(partial)\n",
    "\n",
    "def microaggregation_table(df, k=2):\n",
    "    df_copy = df.copy()\n",
    "    for col in df_copy.select_dtypes(include=[np.number]).columns:\n",
    "        df_copy[col] = microaggregation_row(df_copy[[col]], k)[col]\n",
    "    return df_copy\n",
    "\n",
    "def differential_privacy(df, epsilon=0.1):\n",
    "    df_copy = df.copy()\n",
    "    for col in df_copy.select_dtypes(include=[np.number]).columns:\n",
    "        df_copy[col] = df_copy[col] + np.random.laplace(0, 1/epsilon, size=len(df))\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "9058a3d3-597a-4ca0-8633-65a85bff45a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymize_by_sensitivity(df, strategies, user_trust, granularity):\n",
    "    df_copy = df\n",
    "    applied_strategy = None\n",
    "\n",
    "    for strategy in strategies:\n",
    "        try:\n",
    "            temp_df = df_copy\n",
    "            if granularity in ['cell', 'column']:\n",
    "                # Attempt to apply the strategy to each column\n",
    "                for column in temp_df.columns:\n",
    "                    if strategy == 'cell_suppression':\n",
    "                        temp_df[column] = cell_suppression(temp_df, column)\n",
    "                    elif strategy == 'differential_privacy_column':\n",
    "                        temp_df[column] = differential_privacy_column(temp_df, column)\n",
    "                    elif strategy == 'top_bottom_coding':\n",
    "                        temp_df[column] = top_bottom_coding(temp_df, column)\n",
    "                    elif strategy == 'microaggregation':\n",
    "                        temp_df[column] = microaggregation_row(temp_df[[column]])[column]\n",
    "                    elif strategy == 'noise_injection':\n",
    "                        temp_df[column] = noise_injection(temp_df, column)\n",
    "                    elif strategy == 'generalization':\n",
    "                        temp_df[column] = generalization_column(temp_df, column)\n",
    "                    elif strategy == 'binning':\n",
    "                        temp_df[column] = binning(temp_df, column, bin_size=10)\n",
    "                    elif strategy == 'full_masking':\n",
    "                        temp_df[column] = full_masking_cell(temp_df, column)\n",
    "                    elif strategy == 'partial_masking':\n",
    "                        temp_df[column] = partial_masking_cell(temp_df, column)\n",
    "                    elif strategy == 'no_transformation':\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unknown strategy: {strategy}\")\n",
    "\n",
    "            elif granularity == 'row':\n",
    "                if strategy == 'full_masking':\n",
    "                    temp_df.iloc[:, :] = full_masking_row(temp_df).values\n",
    "                elif strategy == 'partial_masking':\n",
    "                    temp_df.iloc[:, :] = partial_masking_row(temp_df).values\n",
    "                elif strategy == 'microaggregation':\n",
    "                    temp_df = microaggregation_row(temp_df)\n",
    "                elif strategy == 'no_transformation':\n",
    "                    continue\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown strategy: {strategy}\")\n",
    "\n",
    "            elif granularity == 'table':\n",
    "                if strategy == 'full_masking':\n",
    "                    temp_df = full_masking_table(temp_df)\n",
    "                elif strategy == 'partial_masking':\n",
    "                    temp_df = partial_masking_table(temp_df)\n",
    "                elif strategy == 'microaggregation':\n",
    "                    temp_df = microaggregation_table(temp_df)\n",
    "                elif strategy == 'differential_privacy':\n",
    "                    temp_df = differential_privacy(temp_df)\n",
    "                elif strategy == 'no_transformation':\n",
    "                    continue\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown strategy: {strategy}\")\n",
    "\n",
    "            # If no exception occurred, commit changes\n",
    "            df_copy = temp_df\n",
    "            applied_strategy = strategy\n",
    "            break\n",
    "\n",
    "        except Exception as e:\n",
    "            continue  # Try next strategy if this one fails\n",
    "\n",
    "    return df_copy, applied_strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "0ba757fb-a110-4327-b85d-f42955005398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_sensitivity_level(df, sensitivity_df):\n",
    "    # Define ranking\n",
    "    sensitivity_rank = {'Low': 1, 'Moderate': 2, 'High': 3}\n",
    "    reverse_rank = {v: k for k, v in sensitivity_rank.items()}\n",
    "    cols=list(df.columns)\n",
    "    cs = [int(item) for item in cols]\n",
    "    # Filter sensitivity_df to only relevant columns\n",
    "    matched = sensitivity_df[sensitivity_df['Attr_id'].isin(cs)]\n",
    "    # print(matched)\n",
    "    if matched.empty:\n",
    "        raise ValueError(\"No matching columns found between DataFrame and sensitivity mapping.\")\n",
    "\n",
    "    # # Map sensitivity levels to numeric and get max\n",
    "    matched['level_rank'] = matched['Sensitivity_Level'].map(sensitivity_rank)\n",
    "\n",
    "    # print(matched['level_rank'])\n",
    "    max_level_num = matched['level_rank'].max()\n",
    "\n",
    "    return reverse_rank[max_level_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "5552d364-7248-4bdd-bacd-b94e0871119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_anonymization_score(original_df, anonymized_df):\n",
    "    assert original_df.shape == anonymized_df.shape, \"DataFrames must be the same shape\"\n",
    "    \n",
    "    n_rows, n_cols = original_df.shape\n",
    "    total_cells = n_rows * n_cols\n",
    "    total_distance = 0\n",
    "\n",
    "    def delta(orig, anon):\n",
    "        if pd.isnull(anon) or anon in ['*', '****', 'REDACTED', 'SUPPRESSED']:\n",
    "            return 1.0\n",
    "        if orig == anon:\n",
    "            return 0.0\n",
    "        # For generalized ranges like \"30-40\"\n",
    "        if isinstance(anon, str) and '-' in anon:\n",
    "            return 0.5\n",
    "        # For numeric values: compute relative difference\n",
    "        try:\n",
    "            orig_val = float(orig)\n",
    "            anon_val = float(anon)\n",
    "            if orig_val == 0:\n",
    "                return 1.0  # avoid division by zero\n",
    "            return min(1.0, abs(orig_val - anon_val) / abs(orig_val))\n",
    "        except:\n",
    "            return 1.0  # fallback for completely different strings\n",
    "\n",
    "    for col in original_df.columns:\n",
    "        for orig, anon in zip(original_df[col], anonymized_df[col]):\n",
    "            total_distance += delta(orig, anon)\n",
    "\n",
    "    anonymization_score = total_distance / total_cells\n",
    "    utility_retained = 1 - anonymization_score\n",
    "\n",
    "    return anonymization_score, utility_retained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "6316a0c1-654f-4abf-aa9c-d30a9226000d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Type ------ row\n",
      "KYU Score ------ Low\n",
      "Sensitivity Level ------ High\n",
      "Strategies ----- ['full_masking']\n",
      "0    [XXXX, XXXX, XXXX, XXXX, XXXX, XXXX, XXXX]\n",
      "dtype: object\n",
      "Applied--- None\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/ts61208d79v9vfwpxlybsqyh0000gn/T/ipykernel_68264/3884888596.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matched['level_rank'] = matched['Sensitivity_Level'].map(sensitivity_rank)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import sqlite3\n",
    "\n",
    "user_id=2\n",
    "# Create in-memory SQLite database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "data_df.to_sql(\"data_df\", conn, index=False, if_exists=\"replace\")\n",
    "\n",
    "# Run query\n",
    "# query = 'SELECT \"594\",\"601\",\"621\",\"745\",\"753\",\"755\",\"1341\",\"27\",\"29\",\"124\",\"5\",\"9\" FROM data_df'\n",
    "query = 'SELECT \"1455\",\"1198\",\"924\",\"21\",\"1524\",\"333\",\"351\" FROM data_df where \"2\" in (\"Gadag\")'#moderate\n",
    "# query = 'SELECT \"155\" FROM data_df where \"2\" in (\"Gadag\")'#low\n",
    "\n",
    "result = pd.read_sql_query(query, conn)\n",
    "result_type = run_user_query(result)\n",
    "conn.close()\n",
    "print(\"Result Type ------\", result_type)\n",
    "pseudo_map={}\n",
    "# print(sensitivity_df.columns)\n",
    "quasi_identifiers=quasi\n",
    "sensitive_column=sensi\n",
    "kyu_score = kyu_df.loc[kyu_df['ID'] == user_id, 'KYU_Score'].values[0]\n",
    "print(\"KYU Score ------\", kyu_score)\n",
    "\n",
    "resulting_columns = result.columns.tolist()\n",
    "if result_type == 'cell':\n",
    "    result1=sensitivity_df[sensitivity_df['Attr_id'] == int(resulting_columns[0][1:-1])]\n",
    "    # print(result1)\n",
    "    sense=list(result1['Sensitivity_Level'])[0]\n",
    "else:\n",
    "    sense=get_max_sensitivity_level(result, sensitivity_df)\n",
    "    \n",
    "print(\"Sensitivity Level ------\",sense)\n",
    "\n",
    "strategies=select_strategy(result_type,sense.lower(),kyu_score.lower())\n",
    "\n",
    "print(\"Strategies -----\",strategies)\n",
    "original_df=result.copy()\n",
    "anonymized_df,ds = anonymize_by_sensitivity(result,strategies,kyu_score,result_type)\n",
    "print(\"Applied---\",ds)\n",
    "composite,rs = calculate_anonymization_score(original_df, anonymized_df)\n",
    "\n",
    "print(composite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "f431521f-fcca-40d3-9448-6800d0d9fa76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1455</th>\n",
       "      <th>1198</th>\n",
       "      <th>924</th>\n",
       "      <th>21</th>\n",
       "      <th>1524</th>\n",
       "      <th>333</th>\n",
       "      <th>351</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>11</td>\n",
       "      <td>151193.6</td>\n",
       "      <td>13</td>\n",
       "      <td>8.37</td>\n",
       "      <td>698.0</td>\n",
       "      <td>548951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1455  1198       924  21  1524    333     351\n",
       "0    85    11  151193.6  13  8.37  698.0  548951"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "a3108994-d126-41a3-b16f-1cf6a26c0235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1455</th>\n",
       "      <th>1198</th>\n",
       "      <th>924</th>\n",
       "      <th>21</th>\n",
       "      <th>1524</th>\n",
       "      <th>333</th>\n",
       "      <th>351</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>11</td>\n",
       "      <td>151193.6</td>\n",
       "      <td>13</td>\n",
       "      <td>8.37</td>\n",
       "      <td>698.0</td>\n",
       "      <td>548951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1455  1198       924  21  1524    333     351\n",
       "0    85    11  151193.6  13  8.37  698.0  548951"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anonymized_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
